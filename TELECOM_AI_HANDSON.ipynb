{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "language_info": {
   "name": "sql"
  },
  "lastEditStatus": {
   "notebookId": "4t4soww6yy5sledq2kcm",
   "authorId": "3933357949396",
   "authorName": "TTAKAHASHI",
   "authorEmail": "tatsuya.takahashi@snowflake.com",
   "sessionId": "c42632f2-6b79-4aa2-9274-f12545e53c57",
   "lastEditTime": 1772085196397
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "# 通信会社 ネットワーク品質 AI エージェント ハンズオン\n",
    "\n",
    "このハンズオンでは、Snowflake の AI 機能を使って**エリアマスタ、通信品質データ、設備キャパシティデータ、気象データ**の整備から **「自然言語で質問できる AI エージェント作成」** までを一気通貫で構築します。\n",
    "\n",
    "### 今日つくるもの\n",
    "\n",
    "携帯電話通信会社のネットワーク品質データ（通信速度・遅延・接続成功率・トラフィック量など）を横断的に分析できる AI エージェントです。  \n",
    "完成すると、例えばこんな質問に自然言語で答えてくれます：\n",
    "\n",
    "> 「2025年の東京エリアの通信速度推移を月別で可視化して。気温との相関も見たい」  \n",
    "> 「現在設備が逼迫しているエリアと、そのトラフィック推移を教えて」  \n",
    "> 「関東地方のエリア一覧とそれぞれの特徴を教えて」  \n",
    "> 「雨の日と晴れの日で通信品質にどんな違いがある？」\n",
    "\n",
    "---\n",
    "\n",
    "### ハンズオンの流れ（所要時間：約60分 ＋ 応用25分）\n",
    "\n",
    "| Step | やること | 学べる Snowflake 機能 | 所要時間 |\n",
    "|:----:|----------|----------------------|:--------:|\n",
    "| 1 | AI でエリアマスタを整備 | AI_CLASSIFY / AI_COMPLETE | 10分 |\n",
    "| 2 | 気象データを取り込む | Snowflake Marketplace | 10分 |\n",
    "| 3 | エリアの意味検索を可能にする | Cortex Search Service | 10分 |\n",
    "| 4 | データの意味を定義する | Semantic View（Cortex Analyst） | 20分 |\n",
    "| 5 | AI エージェントを組み立てる | Cortex Agent | 15分 |\n",
    "| 6 | 動かしてみよう！ | Cortex Agent UI | 5分 |\n",
    "| 7 | 【応用】カスタムモデルで予兆検知 | Snowpark ML / Container Runtime / Model Registry | 25分 |\n",
    "\n",
    "> **Note**: Step 7 は応用編です。時間に余裕がある場合にチャレンジしてください。Step 1〜6 だけでも十分にハンズオンは完結します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "name": "cell2"
   },
   "source": [
    "## Step 0: 事前準備\n",
    "使用するデータベース・スキーマ・ウェアハウスを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "name": "cell3",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "USE DATABASE TELECOM_AI_HANDSON;\n",
    "USE SCHEMA ANALYTICS;\n",
    "USE WAREHOUSE COMPUTE_WH;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "name": "cell4"
   },
   "source": [
    "---\n",
    "## Step 1: AI でエリアマスタを整備する\n",
    "\n",
    "現在のエリアマスタ（`RAW.AREA_MASTER`）には、エリアID・エリア名・地方名しかありません。  \n",
    "ここに Snowflake の **AI SQL 関数** を使って、2つの情報を自動で追加します。\n",
    "\n",
    "### 追加する情報\n",
    "\n",
    "#### 1. エリアタイプの自動分類 — `AI_CLASSIFY`\n",
    "\n",
    "エリア名だけを見て、AI が自動的にエリアタイプを判定します。  \n",
    "あらかじめ定義した **5つのタイプ** に分類します（MECE＝漏れなくダブりなく）。\n",
    "\n",
    "| エリアタイプ | どんなエリア？ |\n",
    "|-------------|---------------|\n",
    "| 都心ビジネス | オフィス街、駅前商業地区、高層ビル密集地 |\n",
    "| 商業・繁華街 | ショッピングモール、繁華街、娯楽施設集中地 |\n",
    "| 住宅地 | マンション・戸建て住宅が中心の生活エリア |\n",
    "| 観光・ウォーターフロント | 観光地、海辺、リゾート、歴史的エリア |\n",
    "| 郊外・地方 | 工業地帯、農村部、山間地、人口密度が低いエリア |\n",
    "\n",
    "#### 2. エリア特性説明文の自動生成 — `AI_COMPLETE`\n",
    "\n",
    "エリア名と地方名から、そのエリアの **通信需要の特性や課題を説明する文章（約300文字）** を AI が自動で生成します。\n",
    "\n",
    "> **ポイント**: `AI_CLASSIFY` はラベル＋説明文を渡すだけで分類してくれるので、従来のルールベースのロジックを書く必要がありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "name": "cell5",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM TELECOM_AI_HANDSON.RAW.AREA_MASTER;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "name": "cell6"
   },
   "source": [
    "それでは実行しましょう。エリア数にもよりますが、**約1〜2分** で完了します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "name": "cell7",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE TELECOM_AI_HANDSON.ANALYTICS.AI_AREA_MASTER AS\n",
    "SELECT \n",
    "    AREA_ID,\n",
    "    AREA_NAME,\n",
    "    REGION_NAME,\n",
    "    REGION_CODE,\n",
    "    -- ① AI_CLASSIFY関数でエリアタイプを分類（MECE）\n",
    "    AI_CLASSIFY(\n",
    "        AREA_NAME,\n",
    "        [\n",
    "            {'label': '都心ビジネス', 'description': 'オフィス街、駅前商業地区、高層ビル密集地、ビジネス中心地'},\n",
    "            {'label': '商業・繁華街', 'description': 'ショッピングモール、繁華街、娯楽施設集中地、歓楽街'},\n",
    "            {'label': '住宅地', 'description': 'マンション・戸建て住宅が中心の生活エリア、ベッドタウン'},\n",
    "            {'label': '観光・ウォーターフロント', 'description': '観光地、海辺、リゾート、歴史的エリア、臨海地区、湾岸'},\n",
    "            {'label': '郊外・地方', 'description': '工業地帯、農村部、山間地、人口密度が低いエリア、地方都市郊外'}\n",
    "        ],\n",
    "        {'task_description': '日本の携帯電話通信エリア名から最も適切なエリアタイプに分類してください'}\n",
    "    ):labels[0]::VARCHAR AS AREA_TYPE,\n",
    "    -- ② AI_COMPLETE関数でエリア特性説明文生成\n",
    "    TRIM(SNOWFLAKE.CORTEX.AI_COMPLETE(\n",
    "        'llama3.1-405b',\n",
    "        '以下の携帯電話通信エリアについて、通信需要の特性や課題を説明する文章（300文字程度）を日本語で1つ作成してください。\n",
    "         エリア名: ' || AREA_NAME || '\n",
    "         地方: ' || COALESCE(REGION_NAME, '不明') || '\n",
    "         説明文:'\n",
    "    )) AS AREA_DESCRIPTION,\n",
    "    CURRENT_TIMESTAMP() AS CREATED_AT\n",
    "FROM TELECOM_AI_HANDSON.RAW.AREA_MASTER;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000009",
   "metadata": {
    "name": "cell8"
   },
   "source": [
    "### 結果を見てみましょう\n",
    "\n",
    "AI が生成した `AREA_TYPE`（エリアタイプ）と `AREA_DESCRIPTION`（エリア特性説明文）を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "name": "cell9",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM TELECOM_AI_HANDSON.ANALYTICS.AI_AREA_MASTER;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "name": "cell10"
   },
   "source": [
    "### エリアタイプ分類の精度を確認\n",
    "\n",
    "5つのエリアタイプにバランスよく分類されているか確認しましょう。  \n",
    "偏りがある場合は、`AI_CLASSIFY` に渡すエリアタイプの `description` を調整することで精度を改善できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000012",
   "metadata": {
    "name": "cell11",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    AREA_TYPE,\n",
    "    COUNT(*) AS AREA_COUNT\n",
    "FROM TELECOM_AI_HANDSON.ANALYTICS.AI_AREA_MASTER\n",
    "GROUP BY AREA_TYPE\n",
    "ORDER BY AREA_COUNT DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000015",
   "metadata": {
    "name": "cell12"
   },
   "source": [
    "---\n",
    "## Step 2: 気象データを取り込む（Snowflake Marketplace）\n",
    "\n",
    "通信品質は天候に大きく左右されます。  \n",
    "雨天時は電波の減衰が増し通信品質が低下、台風時はさらに顕著 — こうした **天候×通信品質の分析** を可能にするため、  \n",
    "Snowflake Marketplace の **気象データ** を取り込みます。\n",
    "\n",
    "### データソース\n",
    "\n",
    "**Weather Source LLC: Frostbyte** が提供するグローバル気象データを使用します。  \n",
    "日本（JP）の日次気象データを 2019年〜 取得できます。\n",
    "\n",
    "### なぜテーブルを作るのか？\n",
    "\n",
    "元データは華氏・インチ単位で、グローバルデータが含まれています。  \n",
    "通信品質データと結合するには **日本のデータのみを抽出し、メートル法に変換して日付ごとに1行** にする必要があるため、  \n",
    "全国平均に集約するテーブルを作成します。\n",
    "\n",
    "| 集約カラム | 計算方法 | 説明 |\n",
    "|------------|----------|------|\n",
    "| 平均気温 | AVG | 全国の観測所の平均（℃に変換） |\n",
    "| 最高気温 | MAX | 全国で最も高かった気温（℃に変換） |\n",
    "| 最低気温 | MIN | 全国で最も低かった気温（℃に変換） |\n",
    "| 降水量 | AVG | 全国平均の降水量（mmに変換） |\n",
    "| 湿度 | AVG | 全国平均の湿度 |\n",
    "| 日照時間 | AVG | 全国平均の日射量 |\n",
    "| 降雪量 | SUM | 全国の降雪量合計（cmに変換） |\n",
    "| 風速 | AVG | 全国平均の風速（km/hに変換） |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000016",
   "metadata": {
    "name": "cell13",
    "language": "sql"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE TELECOM_AI_HANDSON.ANALYTICS.DAILY_WEATHER AS\nSELECT\n    DATE_VALID_STD                                                      AS WEATHER_DATE,\n    ROUND(AVG((AVG_TEMPERATURE_AIR_2M_F - 32) * 5/9), 1)                AS AVG_TEMPERATURE,\n    ROUND(MAX((MAX_TEMPERATURE_AIR_2M_F - 32) * 5/9), 1)                AS MAX_TEMPERATURE,\n    ROUND(MIN((MIN_TEMPERATURE_AIR_2M_F - 32) * 5/9), 1)                AS MIN_TEMPERATURE,\n    ROUND(AVG(TOT_PRECIPITATION_IN * 25.4), 1)                          AS AVG_RAINFALL,\n    ROUND(AVG(AVG_HUMIDITY_RELATIVE_2M_PCT), 1)                         AS AVG_HUMIDITY,\n    ROUND(AVG(AVG_RADIATION_SOLAR_TOTAL_WPM2), 2)                       AS AVG_SUNLIGHT_HOURS,\n    ROUND(SUM(TOT_SNOWFALL_IN * 25.4), 1)                               AS TOTAL_SNOWFALL,\n    ROUND(AVG(AVG_WIND_SPEED_10M_MPH * 1.60934), 1)                     AS AVG_WIND_SPEED\nFROM WEATHER_SOURCE_LLC_FROSTBYTE.ONPOINT_ID.HISTORY_DAY\nWHERE COUNTRY = 'JP'\nGROUP BY DATE_VALID_STD\nORDER BY DATE_VALID_STD;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaa4be-32fe-420e-8f8d-a95ba0ec9f37",
   "metadata": {
    "name": "cell14",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM TELECOM_AI_HANDSON.ANALYTICS.DAILY_WEATHER;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000013",
   "metadata": {
    "name": "cell15"
   },
   "source": [
    "---\n",
    "## Step 3: エリアの意味検索を可能にする（Cortex Search）\n",
    "\n",
    "Step 1 で作った `AI_AREA_MASTER` に対して、**Cortex Search Service** を作成します。\n",
    "\n",
    "### Cortex Search とは？\n",
    "\n",
    "テキストの **意味** を理解して検索するサービスです。  \n",
    "キーワードの完全一致ではなく、「こういう意味のものを探して」という検索ができます。\n",
    "\n",
    "例えば「トラフィックが多い都市部のエリア」と聞くと、東京都心や大阪梅田などのエリアがヒットします。\n",
    "\n",
    "### 仕組み\n",
    "\n",
    "エリア名・地方名・エリアタイプ・AI説明文を **1つのテキストに結合** し、  \n",
    "Snowflake の Embedding モデル（`snowflake-arctic-embed-l-v2.0`）でベクトル化して検索可能にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000014",
   "metadata": {
    "name": "cell16",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE CORTEX SEARCH SERVICE TELECOM_AI_HANDSON.ANALYTICS.AREA_SEARCH_SERVICE\n",
    "    ON SEARCH_TEXT\n",
    "    ATTRIBUTES AREA_ID, AREA_NAME, REGION_NAME, AREA_TYPE, AREA_DESCRIPTION\n",
    "    WAREHOUSE = COMPUTE_WH\n",
    "    TARGET_LAG = '1 day'\n",
    "    EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "AS (\n",
    "    SELECT\n",
    "        AREA_ID,\n",
    "        AREA_NAME,\n",
    "        REGION_NAME,\n",
    "        REGION_CODE,\n",
    "        AREA_TYPE,\n",
    "        AREA_DESCRIPTION,\n",
    "        CONCAT(\n",
    "            COALESCE(AREA_NAME, ''), ' ',\n",
    "            COALESCE(REGION_NAME, ''), ' ',\n",
    "            COALESCE(AREA_TYPE, ''), ' ',\n",
    "            COALESCE(AREA_DESCRIPTION, '')\n",
    "        ) AS SEARCH_TEXT\n",
    "    FROM TELECOM_AI_HANDSON.ANALYTICS.AI_AREA_MASTER\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000017",
   "metadata": {
    "name": "cell17"
   },
   "source": [
    "---\n",
    "## Step 4: データの意味を定義する（セマンティックビュー）\n",
    "\n",
    "ここがこのハンズオンの **キモ** です。\n",
    "\n",
    "Cortex Analyst に「通信速度を教えて」と聞いたとき、どのテーブルの・どのカラムを・どう集計すればよいかを  \n",
    "AI が理解できるように、**データの意味（セマンティクス）** を定義します。\n",
    "\n",
    "### セマンティックビューで定義すること\n",
    "\n",
    "| 定義項目 | 何を定義する？ | 具体例 |\n",
    "|----------|---------------|--------|\n",
    "| **テーブル** | 分析対象のテーブルとその説明 | NETWORK_QUALITY, EQUIPMENT_STATUS, WEATHER |\n",
    "| **リレーションシップ** | テーブル間の結合条件 | 計測日 = 気象観測日 |\n",
    "| **ファクト** | 集計対象の数値カラム | 通信速度、遅延、トラフィック量、気温 |\n",
    "| **ディメンション** | 分析の切り口となる属性 | エリア名、地方、日付 |\n",
    "| **メトリクス** | よく使う集計パターン | 平均ダウンロード速度＝AVG(下り速度) |\n",
    "| **シノニム** | 日本語の別名・同義語 | 「通信速度」「下り速度」「ダウンロード速度」 |\n",
    "\n",
    "### 3つのテーブルの関係\n",
    "\n",
    "```\n",
    "              AREA_ID              MEASURE_DATE = WEATHER_DATE\n",
    "NETWORK_QUALITY ───────▶ EQUIPMENT_STATUS    NETWORK_QUALITY ────────────────▶ WEATHER\n",
    "(通信品質)                (設備状況)           (通信品質)                        (気象)\n",
    "```\n",
    "\n",
    "> **ポイント**: シノニムを豊富に定義しておくと、「通信速度」でも「ダウンロード速度」でも「下り」でも同じカラムを参照してくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000018",
   "metadata": {
    "name": "cell18",
    "language": "sql"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE SEMANTIC VIEW TELECOM_AI_HANDSON.ANALYTICS.TELECOM_ANALYST\n\n    -- ========================================\n    -- テーブル定義\n    -- ========================================\n    tables (\n        NETWORK_QUALITY AS TELECOM_AI_HANDSON.ANALYTICS.NETWORK_QUALITY\n            PRIMARY KEY (AREA_ID, MEASURE_DATE)\n            WITH SYNONYMS = ('通信品質', 'ネットワーク品質', '品質データ', '通信データ', 'NW品質', '通信速度データ', 'KPI')\n            COMMENT = '日次ネットワーク品質データ。2022-01-01〜2026-02-24のエリア別日次通信速度・遅延・接続成功率・トラフィック量を含む。',\n\n        EQUIPMENT_STATUS AS TELECOM_AI_HANDSON.ANALYTICS.EQUIPMENT_STATUS\n            PRIMARY KEY (AREA_ID)\n            WITH SYNONYMS = ('設備', '設備状況', '設備データ', '基地局', 'キャパシティ', '設備キャパシティ', '負荷')\n            COMMENT = '設備キャパシティスナップショット（2026-02-24時点）。エリア別の基地局数・最大容量・負荷率・設備ステータスを含む。',\n\n        WEATHER AS TELECOM_AI_HANDSON.ANALYTICS.DAILY_WEATHER\n            PRIMARY KEY (WEATHER_DATE)\n            WITH SYNONYMS = ('気象', '天気', '気象データ', '天気データ', '気温', '降水量', '天候', '気象庁', '気象情報')\n            COMMENT = '全国日次平均気象データ（2015年〜）。気象庁の全観測所データを日別に集約した全国平均の気温・降水量・湿度・日照時間・降雪量・風速。'\n    )\n\n    -- ========================================\n    -- リレーションシップ定義\n    -- ========================================\n    relationships (\n        NQ_EQUIPMENT AS NETWORK_QUALITY(AREA_ID) REFERENCES EQUIPMENT_STATUS(AREA_ID),\n        NQ_WEATHER AS NETWORK_QUALITY(MEASURE_DATE) REFERENCES WEATHER(WEATHER_DATE)\n    )\n\n    -- ========================================\n    -- ファクト定義（数値データ）\n    -- ========================================\n    facts (\n        -- 通信品質ファクト\n        NETWORK_QUALITY.download_speed_fact AS AVG_DOWNLOAD_MBPS\n            COMMENT = '平均ダウンロード速度（Mbps）。下り通信速度。',\n        NETWORK_QUALITY.upload_speed_fact AS AVG_UPLOAD_MBPS\n            COMMENT = '平均アップロード速度（Mbps）。上り通信速度。',\n        NETWORK_QUALITY.latency_fact AS AVG_LATENCY_MS\n            COMMENT = '平均遅延（ミリ秒）。レイテンシ。',\n        NETWORK_QUALITY.connection_success_fact AS CONNECTION_SUCCESS_RATE\n            COMMENT = '接続成功率（%）。100%に近いほど良好。',\n        NETWORK_QUALITY.call_drop_fact AS CALL_DROP_RATE\n            COMMENT = '切断率（%）。0%に近いほど良好。',\n        NETWORK_QUALITY.packet_loss_fact AS PACKET_LOSS_RATE\n            COMMENT = 'パケットロス率（%）。0%に近いほど良好。',\n        NETWORK_QUALITY.traffic_fact AS TOTAL_TRAFFIC_GB\n            COMMENT = '日次総トラフィック量（GB）',\n\n        -- 設備ファクト\n        EQUIPMENT_STATUS.base_station_count_fact AS BASE_STATION_COUNT\n            COMMENT = '基地局数（局）',\n        EQUIPMENT_STATUS.max_capacity_fact AS MAX_CAPACITY_GBPS\n            COMMENT = '最大通信容量（Gbps）',\n        EQUIPMENT_STATUS.current_load_fact AS CURRENT_LOAD_PCT\n            COMMENT = '現在の設備負荷率（%）。100%に近いほど逼迫。',\n\n        -- 気象ファクト\n        WEATHER.avg_temperature_fact AS AVG_TEMPERATURE\n            COMMENT = '全国日平均気温（℃）。全観測所の平均。',\n        WEATHER.max_temperature_fact AS MAX_TEMPERATURE\n            COMMENT = '全国日最高気温（℃）。全観測所の最大値。',\n        WEATHER.min_temperature_fact AS MIN_TEMPERATURE\n            COMMENT = '全国日最低気温（℃）。全観測所の最小値。',\n        WEATHER.avg_rainfall_fact AS AVG_RAINFALL\n            COMMENT = '全国日平均降水量（mm）',\n        WEATHER.avg_humidity_fact AS AVG_HUMIDITY\n            COMMENT = '全国日平均湿度（%）',\n        WEATHER.avg_sunlight_hours_fact AS AVG_SUNLIGHT_HOURS\n            COMMENT = '全国日平均日照時間（時間）',\n        WEATHER.total_snowfall_fact AS TOTAL_SNOWFALL\n            COMMENT = '全国日降雪量合計（cm）',\n        WEATHER.avg_wind_speed_fact AS AVG_WIND_SPEED\n            COMMENT = '全国日平均風速（km/h）'\n    )\n\n    -- ========================================\n    -- ディメンション定義（属性データ）\n    -- ========================================\n    dimensions (\n        -- ========== NETWORK_QUALITY ディメンション ==========\n        NETWORK_QUALITY.area_id AS AREA_ID\n            WITH SYNONYMS = ('エリアID', 'エリアコード', '基地局エリア', 'エリア識別子')\n            COMMENT = 'エリア識別コード（例：AREA_KT_001）',\n        NETWORK_QUALITY.area_name AS AREA_NAME\n            WITH SYNONYMS = ('エリア名', 'エリア', '地域名', '地区名', '基地局エリア名')\n            COMMENT = '通信エリア名。東京都心北部エリア、大阪梅田エリアなどを含む。',\n        NETWORK_QUALITY.region_name AS REGION_NAME\n            WITH SYNONYMS = ('地方', '地方名', 'リージョン', '地域')\n            COMMENT = '地方名（関東、近畿、東海、九州）',\n        NETWORK_QUALITY.measure_date AS MEASURE_DATE\n            WITH SYNONYMS = ('計測日', '測定日', '日付', '対象日')\n            COMMENT = '通信品質を計測した日付（DATE型、2022-01-01〜2026-02-24）',\n        NETWORK_QUALITY.measure_year AS YEAR(MEASURE_DATE)\n            WITH SYNONYMS = ('計測年', '年', '対象年')\n            COMMENT = '計測年（2022〜2026）',\n        NETWORK_QUALITY.measure_month AS MONTH(MEASURE_DATE)\n            WITH SYNONYMS = ('計測月', '月', '対象月')\n            COMMENT = '計測月（1〜12）',\n\n        -- ========== EQUIPMENT_STATUS ディメンション ==========\n        EQUIPMENT_STATUS.area_id AS AREA_ID\n            WITH SYNONYMS = ('エリアID', 'エリアコード')\n            COMMENT = 'エリア識別コード',\n        EQUIPMENT_STATUS.area_name AS AREA_NAME\n            WITH SYNONYMS = ('エリア名', 'エリア')\n            COMMENT = 'エリア名',\n        EQUIPMENT_STATUS.region_name AS REGION_NAME\n            WITH SYNONYMS = ('地方', '地方名')\n            COMMENT = '地方名',\n        EQUIPMENT_STATUS.snapshot_date AS SNAPSHOT_DATE\n            WITH SYNONYMS = ('スナップショット日', '基準日', '設備確認日')\n            COMMENT = '設備データの取得日（2026-02-24）',\n        EQUIPMENT_STATUS.equipment_status AS EQUIPMENT_STATUS\n            WITH SYNONYMS = ('設備ステータス', '設備状態', '設備区分', 'ステータス', '負荷状態')\n            COMMENT = '設備の負荷状態を表すステータス（正常 / 注意 / 逼迫）',\n\n        -- ========== WEATHER ディメンション ==========\n        WEATHER.weather_date AS WEATHER_DATE\n            WITH SYNONYMS = ('観測日', '気象日', '天気の日付', '気象観測日')\n            COMMENT = '気象データの観測日（DATE型、2015年〜）。NETWORK_QUALITYのMEASURE_DATEとリレーションで紐づく。',\n        WEATHER.weather_year AS YEAR(WEATHER_DATE)\n            WITH SYNONYMS = ('観測年', '気象年')\n            COMMENT = '気象データの観測年',\n        WEATHER.weather_month AS MONTH(WEATHER_DATE)\n            WITH SYNONYMS = ('観測月', '気象月')\n            COMMENT = '気象データの観測月（1〜12）'\n    )\n\n    -- ========================================\n    -- メトリクス定義（集計関数）\n    -- ========================================\n    metrics (\n        -- 通信品質メトリクス\n        NETWORK_QUALITY.avg_download_speed AS AVG(NETWORK_QUALITY.download_speed_fact)\n            WITH SYNONYMS = ('平均ダウンロード速度', '平均下り速度', '下り平均', '平均通信速度')\n            COMMENT = 'ダウンロード速度の平均（Mbps）',\n        NETWORK_QUALITY.avg_upload_speed AS AVG(NETWORK_QUALITY.upload_speed_fact)\n            WITH SYNONYMS = ('平均アップロード速度', '平均上り速度', '上り平均')\n            COMMENT = 'アップロード速度の平均（Mbps）',\n        NETWORK_QUALITY.avg_latency AS AVG(NETWORK_QUALITY.latency_fact)\n            WITH SYNONYMS = ('平均遅延', '平均レイテンシ', 'レイテンシ平均')\n            COMMENT = '遅延の平均（ms）',\n        NETWORK_QUALITY.avg_connection_success AS AVG(NETWORK_QUALITY.connection_success_fact)\n            WITH SYNONYMS = ('平均接続成功率', '接続成功率平均', '接続率')\n            COMMENT = '接続成功率の平均（%）',\n        NETWORK_QUALITY.avg_call_drop AS AVG(NETWORK_QUALITY.call_drop_fact)\n            WITH SYNONYMS = ('平均切断率', '切断率平均', '通話切断率')\n            COMMENT = '切断率の平均（%）',\n        NETWORK_QUALITY.avg_packet_loss AS AVG(NETWORK_QUALITY.packet_loss_fact)\n            WITH SYNONYMS = ('平均パケットロス率', 'パケロス平均', 'ロス率')\n            COMMENT = 'パケットロス率の平均（%）',\n        NETWORK_QUALITY.total_traffic AS SUM(NETWORK_QUALITY.traffic_fact)\n            WITH SYNONYMS = ('総トラフィック', '合計トラフィック', 'トラフィック合計', '総通信量')\n            COMMENT = 'トラフィック量の合計（GB）',\n        NETWORK_QUALITY.avg_daily_traffic AS AVG(NETWORK_QUALITY.traffic_fact)\n            WITH SYNONYMS = ('日平均トラフィック', '日次平均トラフィック', '平均日次通信量')\n            COMMENT = '日次トラフィック量の平均（GB）',\n\n        -- 設備メトリクス\n        EQUIPMENT_STATUS.total_base_stations AS SUM(EQUIPMENT_STATUS.base_station_count_fact)\n            WITH SYNONYMS = ('総基地局数', '合計基地局数', '基地局数合計')\n            COMMENT = '基地局数の合計（局）',\n        EQUIPMENT_STATUS.total_capacity AS SUM(EQUIPMENT_STATUS.max_capacity_fact)\n            WITH SYNONYMS = ('総容量', '合計容量', '最大容量合計')\n            COMMENT = '最大通信容量の合計（Gbps）',\n        EQUIPMENT_STATUS.avg_load AS AVG(EQUIPMENT_STATUS.current_load_fact)\n            WITH SYNONYMS = ('平均負荷率', '負荷率平均', '平均設備負荷')\n            COMMENT = '設備負荷率の平均（%）',\n\n        -- 気象メトリクス\n        WEATHER.period_avg_temperature AS AVG(WEATHER.avg_temperature_fact)\n            WITH SYNONYMS = ('平均気温', '気温平均', '平均温度')\n            COMMENT = '期間内の全国平均気温（℃）',\n        WEATHER.period_max_temperature AS MAX(WEATHER.max_temperature_fact)\n            WITH SYNONYMS = ('最高気温', '最高温度', '期間最高気温')\n            COMMENT = '期間中の全国最高気温（℃）',\n        WEATHER.period_min_temperature AS MIN(WEATHER.min_temperature_fact)\n            WITH SYNONYMS = ('最低気温', '最低温度', '期間最低気温')\n            COMMENT = '期間中の全国最低気温（℃）',\n        WEATHER.period_avg_rainfall AS AVG(WEATHER.avg_rainfall_fact)\n            WITH SYNONYMS = ('平均降水量', '降水量平均')\n            COMMENT = '期間内の全国平均降水量（mm）',\n        WEATHER.period_avg_humidity AS AVG(WEATHER.avg_humidity_fact)\n            WITH SYNONYMS = ('平均湿度', '湿度平均')\n            COMMENT = '期間内の全国平均湿度（%）',\n        WEATHER.period_avg_sunlight AS AVG(WEATHER.avg_sunlight_hours_fact)\n            WITH SYNONYMS = ('平均日照時間', '日照時間平均')\n            COMMENT = '期間内の全国平均日照時間（時間）',\n        WEATHER.period_total_snowfall AS SUM(WEATHER.total_snowfall_fact)\n            WITH SYNONYMS = ('総降雪量', '合計降雪量', '累積降雪量')\n            COMMENT = '期間内の全国降雪量合計（cm）',\n        WEATHER.period_avg_wind_speed AS AVG(WEATHER.avg_wind_speed_fact)\n            WITH SYNONYMS = ('平均風速', '風速平均')\n            COMMENT = '期間内の全国平均風速（km/h）'\n    )\n\n    COMMENT = '携帯電話通信会社のネットワーク品質・設備・気象分析のためのセマンティックビュー。関東・近畿・東海・九州の50エリアの通信品質データを含む。2022年〜の日次通信品質データ（下り/上り速度、遅延、接続成功率、切断率、パケットロス率、トラフィック量）、2026-02-24時点の設備キャパシティスナップショット（基地局数、最大容量、負荷率）、および気象庁の全国日次平均気象データ（気温・降水量・湿度・日照時間・降雪量等）を統合。計測日と気象観測日がリレーションで紐づき、天候と通信品質の相関分析が可能。';"
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000019",
   "metadata": {
    "name": "cell19"
   },
   "source": [
    "### セマンティックビューの確認\n",
    "\n",
    "正しく定義できたか確認しましょう。テーブル・ファクト・ディメンション・メトリクスの一覧が表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000020",
   "metadata": {
    "name": "cell20",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "DESCRIBE SEMANTIC VIEW TELECOM_ANALYST;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000021",
   "metadata": {
    "name": "cell21"
   },
   "source": [
    "---\n",
    "## Step 5: AI エージェントを組み立てる（Cortex Agent）\n",
    "\n",
    "いよいよエージェントを組み立てます。  \n",
    "ここまで作ってきた **Cortex Search** と **Cortex Analyst** を組み合わせて、  \n",
    "1つの **AI エージェント** にまとめます。\n",
    "\n",
    "### エージェントの仕組み\n",
    "\n",
    "```\n",
    "ユーザーの質問\n",
    "     │\n",
    "     ▼\n",
    "┌─────────────────────────┐\n",
    "│   Telecom Agent        │\n",
    "│  （オーケストレーター）   │\n",
    "│                        │\n",
    "│  質問の意図を判断して      │\n",
    "│  適切なツールを選択        │\n",
    "└────┬──────────┬─────────┘\n",
    "     │          │\n",
    "     ▼          ▼\n",
    "┌─────────┐ ┌──────────────┐\n",
    "│ Cortex  │ │   Cortex     │\n",
    "│ Search  │ │  Analyst     │\n",
    "│         │ │              │\n",
    "│エリア情報│  │通信品質・設備・│\n",
    "│の意味検索│ │気象の数値分析  │\n",
    "└─────────┘ └──────────────┘\n",
    "```\n",
    "\n",
    "### ツールの使い分け\n",
    "\n",
    "| 質問の種類 | 使われるツール | 例 |\n",
    "|-----------|---------------|----|\n",
    "| エリアの特徴・情報を知りたい | **Cortex Search** | 「関東のエリア一覧を教えて」 |\n",
    "| 数値の集計・分析をしたい | **Cortex Analyst** | 「2025年の月別通信速度は？」 |\n",
    "| 両方が必要 | **Search → Analyst** | 「逼迫エリアのトラフィック推移は？」 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000022",
   "metadata": {
    "name": "cell22",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE AGENT TELECOM_AI_HANDSON.ANALYTICS.TELECOM_AGENT\n",
    "    COMMENT = '携帯電話通信会社のネットワーク品質・設備・気象分析とエリア検索を行うエージェント'\n",
    "FROM SPECIFICATION $$\n",
    "{\n",
    "  \"models\": {\n",
    "    \"orchestration\": \"\"\n",
    "  },\n",
    "  \"instructions\": {\n",
    "    \"response\": \"あなたは携帯電話通信会社のネットワーク品質アナリストです。ユーザーからの質問に対して、通信品質データ（下り/上り速度、遅延、接続成功率、切断率、パケットロス率、トラフィック量）、設備キャパシティデータ（基地局数、最大容量、負荷率）、気象データを活用して回答してください。数値データは適切にフォーマットして表示してください（例：速度はMbps表記、トラフィックはGB表記、比率は%表記）。エリア名は正確に記載してください。分析結果には根拠となるデータを含めてください。日本語で丁寧に回答してください。可能であれば視覚化を提供してください。時系列のトレンドは線グラフをデフォルトとし、エリア比較は棒グラフを使用してください。天候と通信品質の関係（雨天時の品質低下、気温とトラフィック量の相関など）にも注意して分析してください。\",\n",
    "    \"orchestration\": \"エリアの詳細情報（エリア名、地方、エリアタイプ、AI説明文など）を検索する場合はcortex searchを使用し、通信品質・設備・気象の数値分析にはcortex analystを使用してください。複合的な質問の場合は、まずcortex searchでエリアを特定し、その結果をcortex analystに渡して分析してください。気温や天候と通信品質の関係を聞かれた場合は、cortex analystでネットワーク品質データと気象データを組み合わせて分析してください。\",\n",
    "    \"sample_questions\": [\n",
    "      {\n",
    "        \"question\": \"2025年の東京都心エリアの下り通信速度推移を月別で可視化してください。気温との相関も見たいです。\"\n",
    "      },\n",
    "      {\n",
    "        \"question\": \"トラフィック量が最も多い月はいつですか？どのエリアが特にトラフィックが集中しますか？\"\n",
    "      },\n",
    "      {\n",
    "        \"question\": \"現在設備が逼迫しているエリアを教えてください。それぞれのエリアの過去のトラフィック推移も見せてください。\"\n",
    "      },\n",
    "      {\n",
    "        \"question\": \"関東地方のエリア一覧とそれぞれの特徴を教えてください。\"\n",
    "      },\n",
    "      {\n",
    "        \"question\": \"2024年と2025年でトラフィックが大きく増加したエリアトップ5を教えてください。\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"tools\": [\n",
    "    {\n",
    "      \"tool_spec\": {\n",
    "        \"type\": \"cortex_analyst_text_to_sql\",\n",
    "        \"name\": \"TELECOM_ANALYST\",\n",
    "        \"description\": \"携帯電話通信会社のネットワーク品質データ、設備キャパシティデータ、全国日次気象データをクエリして分析します。下り/上り通信速度、遅延、接続成功率、切断率、パケットロス率、トラフィック量の集計や、気温・降水量と通信品質の相関分析に使用します。2022年〜2026年2月の日次通信品質データ、2026年2月時点の設備キャパシティスナップショット、2015年〜の全国平均気象データを含みます。\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"tool_spec\": {\n",
    "        \"type\": \"cortex_search\",\n",
    "        \"name\": \"AREA_SEARCH\",\n",
    "        \"description\": \"携帯電話通信エリアのマスタからエリア情報を検索します。エリア名、地方名、AIが分類したエリアタイプ（都心ビジネス、商業・繁華街、住宅地、観光・ウォーターフロント、郊外・地方）、AIが生成したエリア特性説明文などのテキスト検索に使用します。\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"tool_resources\": {\n",
    "    \"TELECOM_ANALYST\": {\n",
    "      \"semantic_view\": \"TELECOM_AI_HANDSON.ANALYTICS.TELECOM_ANALYST\"\n",
    "    },\n",
    "    \"AREA_SEARCH\": {\n",
    "      \"name\": \"TELECOM_AI_HANDSON.ANALYTICS.AREA_SEARCH_SERVICE\",\n",
    "      \"max_results\": 10\n",
    "    }\n",
    "  }\n",
    "}\n",
    "$$;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000023",
   "metadata": {
    "name": "cell23"
   },
   "source": [
    "### エージェントの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000024",
   "metadata": {
    "name": "cell24",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "SHOW AGENTS IN SCHEMA TELECOM_AI_HANDSON.ANALYTICS;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000025",
   "metadata": {
    "name": "cell25"
   },
   "source": [
    "---\n",
    "## Step 6: 動かしてみよう！\n",
    "\n",
    "エージェントが完成しました！Snowsight の **Cortex Agent UI** から以下のような質問を試してみましょう。\n",
    "\n",
    "### 試してみたい質問例\n",
    "\n",
    "**通信品質分析**\n",
    "- 「2025年の東京都心エリアの下り通信速度推移を月別で可視化してください。気温との相関も見たいです。」\n",
    "- 「2024年と2025年でトラフィックが大きく増加したエリアトップ5を教えてください。」\n",
    "\n",
    "**天候×通信品質**\n",
    "- 「降水量が多い日と少ない日で通信速度にどんな違いがありますか？」\n",
    "- 「台風シーズン（8-9月）の通信品質への影響を分析してください。」\n",
    "\n",
    "**設備管理**\n",
    "- 「現在設備が逼迫しているエリアを教えてください。それぞれの過去のトラフィック推移も見せてください。」\n",
    "- 「設備負荷率が注意レベルのエリアはどこですか？」\n",
    "\n",
    "**エリア検索**\n",
    "- 「関東地方のエリア一覧とそれぞれの特徴を教えてください。」\n",
    "- 「観光地エリアの通信品質の傾向を教えてください。」\n",
    "\n",
    "**Web検索**\n",
    "- 「2026年に予定されている5G展開計画について教えてください。」\n",
    "- 「最近の通信障害ニュースはありますか？」"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dddc9e-1d48-471c-aa8b-cc1ad0edf888",
   "metadata": {
    "name": "cell48"
   },
   "source": [
    "---\n",
    "## Step 7【応用編】: カスタムモデルで予兆検知（Snowpark ML / Container Runtime）\n",
    "\n",
    "> **前提条件**: この Step は Snowflake Notebook の **Container Runtime** 上で実行します。  \n",
    "> `setup_database.sql` の STEP 12 でコンピュートプールの作成と Notebook への割り当てが完了しています。  \n",
    "> Snowsight の Notebook 設定で **Container Runtime が有効** になっていることを確認してください。  \n",
    "> scikit-learn / XGBoost は Container Runtime に **プリインストール済み** のため、追加インストールは不要です。\n",
    "\n",
    "### この Step でやること\n",
    "\n",
    "1. **IsolationForest** で切断率の異常検知（教師なし）\n",
    "2. **XGBRegressor** でトラフィック量の予測（教師あり）\n",
    "3. 両モデルを **Model Registry** に登録し、推論を実行"
   ],
   "attachments": {}
  },
  {
   "cell_type": "code",
   "id": "f5ff8549-1b29-4262-b875-da50a6854fd1",
   "metadata": {
    "name": "cell49",
    "language": "python"
   },
   "source": [
    "# Container Runtime にプリインストール済みのパッケージを確認\n",
    "# scikit-learn と xgboost が含まれていることを確認します\n",
    "!pip freeze | grep -E \"scikit-learn|xgboost\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "624ff4db-783c-4fb8-9fe8-472109dc7d47",
   "metadata": {
    "name": "cell50",
    "language": "python"
   },
   "source": "# ============================================================\n# データ取得: 通信品質 + 気象データを Pandas に読み込む\n# ============================================================\nimport pandas as pd\nfrom snowflake.snowpark.context import get_active_session\n\nsession = get_active_session()\n\n# 全国平均の日次通信品質 + 気象データを結合して取得\ndf = session.sql(\"\"\"\n    SELECT\n        nq.MEASURE_DATE,\n        AVG(nq.CALL_DROP_RATE)          AS CALL_DROP_RATE,\n        AVG(nq.TOTAL_TRAFFIC_GB)        AS TOTAL_TRAFFIC_GB,\n        AVG(nq.AVG_DOWNLOAD_MBPS)       AS AVG_DOWNLOAD_MBPS,\n        AVG(nq.AVG_LATENCY_MS)          AS AVG_LATENCY_MS,\n        AVG(nq.PACKET_LOSS_RATE)        AS PACKET_LOSS_RATE,\n        AVG(w.AVG_TEMPERATURE)          AS AVG_TEMPERATURE_C,\n        AVG(w.AVG_RAINFALL)             AS PRECIPITATION_MM,\n        AVG(w.AVG_WIND_SPEED)           AS WIND_SPEED_KMH\n    FROM TELECOM_AI_HANDSON.ANALYTICS.NETWORK_QUALITY nq\n    LEFT JOIN TELECOM_AI_HANDSON.ANALYTICS.DAILY_WEATHER w\n        ON nq.MEASURE_DATE = w.WEATHER_DATE\n    GROUP BY nq.MEASURE_DATE\n    ORDER BY nq.MEASURE_DATE\n\"\"\").to_pandas()\n\n# 日付型変換・欠損値除去\ndf[\"MEASURE_DATE\"] = pd.to_datetime(df[\"MEASURE_DATE\"])\ndf = df.dropna()\n\n# 訓練 / テスト分割（2025年以降をテスト）\ntrain = df[df[\"MEASURE_DATE\"] < \"2025-01-01\"].copy()\ntest  = df[df[\"MEASURE_DATE\"] >= \"2025-01-01\"].copy()\n\nprint(f\"訓練データ: {len(train)} 日, テストデータ: {len(test)} 日\")\nprint(f\"期間: {train['MEASURE_DATE'].min().date()} ~ {test['MEASURE_DATE'].max().date()}\")\ntrain.head()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "83ccd37d-b4d6-45be-b5cb-122c68a31f16",
   "metadata": {
    "name": "cell51"
   },
   "source": [
    "### パート A: IsolationForest で異常検知\n\n**IsolationForest** は、教師なし学習の異常検知アルゴリズムです。  \nデータポイントを「孤立させるのに必要な分割回数」で異常度を測定します。  \n異常なデータは少ない分割で孤立するため、**異常スコアが高く** なります。\n\n#### IsolationForest の特徴\n\n| 項目 | 内容 |\n|---|---|\n| アルゴリズム | ランダムフォレストベースの孤立検知（教師なし） |\n| ハイパーパラメータ | `n_estimators`（木の数）, `contamination`（異常割合）, `max_features`（特徴量数）等 |\n| 特徴量 | 自由に設計可能（ラグ特徴量・移動平均等も組み合わせられる） |\n| 出力 | 異常スコア（連続値） + 異常ラベル |"
   ],
   "attachments": {}
  },
  {
   "cell_type": "code",
   "id": "2356a70e-f208-4685-9cfa-ab5664d846ae",
   "metadata": {
    "name": "cell52",
    "language": "python"
   },
   "source": [
    "# ============================================================\n",
    "# IsolationForest: 訓練 → Model Registry に登録\n",
    "# ============================================================\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "# --- 特徴量 ---\n",
    "FEATURE_COLS = [\n",
    "    \"CALL_DROP_RATE\", \"AVG_DOWNLOAD_MBPS\", \"AVG_LATENCY_MS\",\n",
    "    \"PACKET_LOSS_RATE\", \"PRECIPITATION_MM\", \"WIND_SPEED_KMH\"\n",
    "]\n",
    "\n",
    "# --- モデル訓練 ---\n",
    "# contamination: 異常と見なすデータの割合（5%）\n",
    "# n_estimators: 決定木の本数（多いほど安定）\n",
    "iso_model = IsolationForest(\n",
    "    n_estimators=200,\n",
    "    contamination=0.05,\n",
    "    max_features=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "iso_model.fit(train[FEATURE_COLS])\n",
    "\n",
    "# --- 訓練データでの異常検知結果を確認 ---\n",
    "train_scores = iso_model.decision_function(train[FEATURE_COLS])\n",
    "train_pred   = iso_model.predict(train[FEATURE_COLS])\n",
    "print(f\"訓練データの異常件数: {(train_pred == -1).sum()} / {len(train_pred)}\")\n",
    "\n",
    "# --- Model Registry に登録 ---\n",
    "# Note: 登録時に UserWarning が数件表示されますが、いずれもエラーではなく正常動作です。\n",
    "#   - relax_version: 依存ライブラリのバージョン制約が緩和される旨の通知（デフォルト動作）\n",
    "#   - sample input: 入出力スキーマ推論に先頭100行のみ使用する旨の通知（全行は不要）\n",
    "# target_platforms=[\"WAREHOUSE\"] でウェアハウスからの推論を有効化\n",
    "reg = Registry(session=session, database_name=\"TELECOM_AI_HANDSON\", schema_name=\"ANALYTICS\")\n",
    "\n",
    "# 既存モデルがあれば削除して再登録（冪等性を確保）\n",
    "try:\n",
    "    reg.delete_model(\"NQ_ISOLATION_FOREST\")\n",
    "    print(\"既存モデル NQ_ISOLATION_FOREST を削除しました\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "iso_mv = reg.log_model(\n",
    "    model=iso_model,\n",
    "    model_name=\"NQ_ISOLATION_FOREST\",\n",
    "    version_name=\"v1\",\n",
    "    conda_dependencies=[\"scikit-learn\"],\n",
    "    comment=\"IsolationForest: 通信品質の異常検知モデル（切断率+気象特徴量）\",\n",
    "    sample_input_data=train[FEATURE_COLS],\n",
    "    target_platforms=[\"WAREHOUSE\"],\n",
    "    metrics={\n",
    "        \"n_estimators\": 200,\n",
    "        \"contamination\": 0.05,\n",
    "        \"train_anomaly_ratio\": float((train_pred == -1).mean())\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✅ Model Registry に登録完了: NQ_ISOLATION_FOREST v1\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "003c6e15-ddb1-464b-b9b9-9de21d942385",
   "metadata": {
    "name": "cell53",
    "language": "python"
   },
   "source": [
    "# ============================================================\n",
    "# IsolationForest: テストデータで推論 → 結果を確認\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "\n",
    "# --- テストデータで推論（ローカルの iso_model を直接使用）---\n",
    "test_pred   = iso_model.predict(test[FEATURE_COLS])\n",
    "test_scores = iso_model.decision_function(test[FEATURE_COLS])\n",
    "\n",
    "test[\"ISO_ANOMALY\"]       = (test_pred == -1)\n",
    "test[\"ISO_ANOMALY_SCORE\"] = test_scores\n",
    "\n",
    "anomaly_days = test[test[\"ISO_ANOMALY\"]]\n",
    "print(f\"テストデータの異常検知結果: {len(anomaly_days)} 日 / {len(test)} 日 を異常と判定\")\n",
    "print(f\"異常日の切断率: 平均 {anomaly_days['CALL_DROP_RATE'].mean():.3f}, \"\n",
    "      f\"最大 {anomaly_days['CALL_DROP_RATE'].max():.3f}\")\n",
    "print(f\"正常日の切断率: 平均 {test[~test['ISO_ANOMALY']]['CALL_DROP_RATE'].mean():.3f}\")\n",
    "\n",
    "# --- Registry 経由の推論（mv.run はウェアハウスで実行）---\n",
    "print(\"\\n--- Registry 経由の推論（mv.run → Warehouse）---\")\n",
    "iso_mv_loaded = reg.get_model(\"NQ_ISOLATION_FOREST\").version(\"v1\")\n",
    "# Snowpark DataFrame に変換して渡す\n",
    "test_sp = session.create_dataframe(test[FEATURE_COLS].head(5))\n",
    "registry_pred = iso_mv_loaded.run(test_sp, function_name=\"predict\")\n",
    "registry_pred.show()\n",
    "\n",
    "# --- 異常日の上位10件を表示 ---\n",
    "anomaly_days[[\"MEASURE_DATE\", \"CALL_DROP_RATE\", \"PRECIPITATION_MM\",\n",
    "              \"WIND_SPEED_KMH\", \"ISO_ANOMALY_SCORE\"]].sort_values(\n",
    "    \"ISO_ANOMALY_SCORE\").head(10)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-5678-9abc-def0-111222333444",
   "metadata": {
    "name": "cell53_explanation"
   },
   "source": [
    "#### 結果の読み方\n",
    "\n",
    "**1. 異常検知のサマリー**\n",
    "\n",
    "```\n",
    "テストデータの異常検知結果: 57 日 / 420 日 を異常と判定\n",
    "異常日の切断率: 平均 0.298, 最大 0.544\n",
    "正常日の切断率: 平均 0.313\n",
    "```\n",
    "\n",
    "- テストデータ 420 日のうち **57 日（約13.6%）** を異常と判定しました。\n",
    "- `contamination=0.05`（5%）で訓練しましたが、テストデータでは異常が多めに検出されています。  \n",
    "  これは **テスト期間（2025年〜）のデータ傾向が訓練期間と異なる** ことを示唆しています。\n",
    "- 異常日の切断率の平均（0.298）が正常日（0.313）より **低い** 点に注目してください。  \n",
    "  IsolationForest は切断率だけでなく **6つの特徴量の組み合わせ** で判定するため、  \n",
    "  「切断率は低いが、降水量や風速が極端な日」なども異常として検出されます。\n",
    "\n",
    "**2. Registry 経由の推論**\n",
    "\n",
    "```\n",
    "output_feature_0:  1 = 正常, -1 = 異常\n",
    "```\n",
    "\n",
    "- Model Registry に登録したモデルを `mv.run()` で呼び出し、ウェアハウス上で推論できることを確認しています。\n",
    "- 5行中 1行が `-1`（異常）と判定されています。降水量 5.5mm・風速 16.5km/h と **気象条件が他の日より悪い** ことが要因です。\n",
    "\n",
    "**3. 異常日の詳細（上位10件）**\n",
    "\n",
    "| カラム | 意味 |\n",
    "|--------|------|\n",
    "| `CALL_DROP_RATE` | 切断率（低いほど良好） |\n",
    "| `PRECIPITATION_MM` | 降水量（mm） |\n",
    "| `WIND_SPEED_KMH` | 風速（km/h） |\n",
    "| `ISO_ANOMALY_SCORE` | 異常スコア（**負の値が大きいほど異常度が高い**） |\n",
    "\n",
    "- スコアが最も低い（異常度が高い）のは **冬季（1月・12月）の降水量0mm + 強風の日** です。  \n",
    "  乾燥・強風という通常と異なる気象パターンが「孤立しやすい」データとして検出されています。\n",
    "- 一方、2025年5〜9月には **降水量 60mm超の大雨の日** も異常として検出されています。\n",
    "- このように IsolationForest は「典型的でないパターン」を多角的に検出できるのが強みです。"
   ],
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "id": "d6ab4981-01d5-4399-b6d9-fba3ca67f6eb",
   "metadata": {
    "name": "cell54"
   },
   "source": [
    "### パート B: XGBRegressor でトラフィック予測\n",
    "\n",
    "**XGBRegressor**（XGBoost の回帰モデル）を使って、トラフィック量を予測します。  \n",
    "Step 3 の `FORECAST` は時系列専用（ARIMA ベース）でしたが、ここでは **特徴量エンジニアリング** を自分で設計し、  \n",
    "気象データ・曜日・月などの特徴量を組み合わせた勾配ブースティング回帰モデルを構築します。\n",
    "\n",
    "#### カスタマイズのポイント\n",
    "\n",
    "| カスタム要素 | 内容 |\n",
    "|---|---|\n",
    "| **ラグ特徴量** | 前日・3日前・7日前のトラフィック量 |\n",
    "| **移動平均** | 直近7日間の移動平均 |\n",
    "| **カレンダー特徴量** | 曜日（0-6）、月（1-12） |\n",
    "| **気象特徴量** | 気温・降水量・風速 |\n",
    "| **ハイパーパラメータ** | `n_estimators`, `max_depth`, `learning_rate` を調整 |"
   ],
   "attachments": {}
  },
  {
   "cell_type": "code",
   "id": "ed9d9b02-3845-41e3-9dba-6289c16d20ab",
   "metadata": {
    "name": "cell55",
    "language": "python",
    "codeCollapsed": false
   },
   "source": [
    "# ============================================================\n",
    "# XGBRegressor: 特徴量エンジニアリング → 訓練 → Registry 登録\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# --- 特徴量エンジニアリング ---\n",
    "def add_features(data):\n",
    "    \"\"\"ラグ特徴量・移動平均・カレンダー特徴量を追加\"\"\"\n",
    "    d = data.copy()\n",
    "    d = d.sort_values(\"MEASURE_DATE\")\n",
    "    # ラグ特徴量\n",
    "    d[\"TRAFFIC_LAG_1\"]  = d[\"TOTAL_TRAFFIC_GB\"].shift(1)\n",
    "    d[\"TRAFFIC_LAG_3\"]  = d[\"TOTAL_TRAFFIC_GB\"].shift(3)\n",
    "    d[\"TRAFFIC_LAG_7\"]  = d[\"TOTAL_TRAFFIC_GB\"].shift(7)\n",
    "    # 移動平均\n",
    "    d[\"TRAFFIC_MA_7\"]   = d[\"TOTAL_TRAFFIC_GB\"].rolling(7).mean()\n",
    "    # カレンダー特徴量\n",
    "    d[\"DAY_OF_WEEK\"]    = d[\"MEASURE_DATE\"].dt.dayofweek\n",
    "    d[\"MONTH\"]          = d[\"MEASURE_DATE\"].dt.month\n",
    "    return d.dropna()\n",
    "\n",
    "train_fe = add_features(train)\n",
    "# テストデータ: 訓練データの末尾と連結してラグ特徴量を計算した後に分離\n",
    "all_data_fe = add_features(pd.concat([train, test], ignore_index=True))\n",
    "test_fe = all_data_fe[all_data_fe[\"MEASURE_DATE\"] >= \"2025-01-01\"].copy()\n",
    "\n",
    "XGB_FEATURES = [\n",
    "    \"TRAFFIC_LAG_1\", \"TRAFFIC_LAG_3\", \"TRAFFIC_LAG_7\", \"TRAFFIC_MA_7\",\n",
    "    \"DAY_OF_WEEK\", \"MONTH\",\n",
    "    \"AVG_TEMPERATURE_C\", \"PRECIPITATION_MM\", \"WIND_SPEED_KMH\"\n",
    "]\n",
    "TARGET = \"TOTAL_TRAFFIC_GB\"\n",
    "\n",
    "# --- モデル訓練 ---\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(\n",
    "    train_fe[XGB_FEATURES], train_fe[TARGET],\n",
    "    eval_set=[(test_fe[XGB_FEATURES], test_fe[TARGET])],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# --- 評価 ---\n",
    "test_fe[\"XGB_PREDICTED\"] = xgb_model.predict(test_fe[XGB_FEATURES])\n",
    "mae  = mean_absolute_error(test_fe[TARGET], test_fe[\"XGB_PREDICTED\"])\n",
    "rmse = np.sqrt(mean_squared_error(test_fe[TARGET], test_fe[\"XGB_PREDICTED\"]))\n",
    "print(f\"テストデータ評価: MAE = {mae:.2f} GB, RMSE = {rmse:.2f} GB\")\n",
    "\n",
    "# --- 特徴量の重要度 ---\n",
    "importance = pd.DataFrame({\n",
    "    \"FEATURE\": XGB_FEATURES,\n",
    "    \"IMPORTANCE\": xgb_model.feature_importances_\n",
    "}).sort_values(\"IMPORTANCE\", ascending=False)\n",
    "print(\"\\n特徴量の重要度:\")\n",
    "print(importance.to_string(index=False))\n",
    "\n",
    "# --- Model Registry に登録 ---\n",
    "# Note: パート A と同様、UserWarning が表示されますがエラーではありません。\n",
    "# 既存モデルがあれば削除して再登録（冪等性を確保）\n",
    "try:\n",
    "    reg.delete_model(\"NQ_TRAFFIC_XGBOOST\")\n",
    "    print(\"既存モデル NQ_TRAFFIC_XGBOOST を削除しました\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# target_platforms=[\"WAREHOUSE\"] でウェアハウスからの推論を有効化\n",
    "xgb_mv = reg.log_model(\n",
    "    model=xgb_model,\n",
    "    model_name=\"NQ_TRAFFIC_XGBOOST\",\n",
    "    version_name=\"v1\",\n",
    "    conda_dependencies=[\"xgboost\"],\n",
    "    comment=\"XGBRegressor: トラフィック予測（ラグ+気象+カレンダー特徴量）\",\n",
    "    sample_input_data=train_fe[XGB_FEATURES],\n",
    "    target_platforms=[\"WAREHOUSE\"],\n",
    "    metrics={\"MAE\": float(mae), \"RMSE\": float(rmse)}\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Model Registry に登録完了: NQ_TRAFFIC_XGBOOST v1\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6-789a-bcde-f012-333444555666",
   "metadata": {
    "name": "cell55_explanation"
   },
   "source": [
    "#### 結果の読み方\n",
    "\n",
    "**1. モデル精度（テストデータ評価）**\n",
    "\n",
    "```\n",
    "テストデータ評価: MAE = 19.94 GB, RMSE = 36.78 GB\n",
    "```\n",
    "\n",
    "| 指標 | 値 | 意味 |\n",
    "|------|-----|------|\n",
    "| **MAE**（Mean Absolute Error） | 19.94 GB | 予測値と実測値の平均的なズレ。トラフィック予測が **平均 ±20GB 程度** の誤差であることを示す |\n",
    "| **RMSE**（Root Mean Squared Error） | 36.78 GB | 大きな外れ値を重く評価した誤差。MAE より大きいため、**一部の日で大きく外す** ケースがあることを示す |\n",
    "\n",
    "日次トラフィック量が数百 GB 規模であることを考えると、MAE 約 20GB は実用的な精度です。  \n",
    "RMSE が MAE の約1.8倍あるため、休日やイベント日など **特異日の予測改善** が精度向上のポイントになります。\n",
    "\n",
    "**2. 特徴量の重要度**\n",
    "\n",
    "XGBoost が予測に各特徴量をどれだけ使ったかを示します（合計 = 1.0）。\n",
    "\n",
    "| 順位 | 特徴量 | 重要度 | 解釈 |\n",
    "|:----:|--------|--------|------|\n",
    "| 1 | `DAY_OF_WEEK`（曜日） | **0.383** | トラフィック量を最も左右するのは **曜日**。平日 vs 休日でトラフィックパターンが大きく異なる |\n",
    "| 2 | `TRAFFIC_LAG_7`（7日前のトラフィック） | **0.363** | 1週間前の同曜日のトラフィックが強い予測因子。**週次の周期性** を捉えている |\n",
    "| 3 | `TRAFFIC_MA_7`（7日間移動平均） | **0.139** | 直近1週間のトレンドも予測に寄与。急増・急減の傾向を反映 |\n",
    "| 4 | `TRAFFIC_LAG_1`（前日トラフィック） | 0.056 | 前日の値も参考にされるが、曜日や週次パターンほどではない |\n",
    "| 5 | `MONTH`（月） | 0.027 | 季節性の影響（夏休み・年末年始など） |\n",
    "| 6-9 | ラグ3日・気温・風速・降水量 | 各0.001〜0.017 | 気象条件の直接的な影響は小さい |\n",
    "\n",
    "上位3つ（曜日 + 7日前ラグ + 移動平均）だけで **全体の約88%** を占めています。  \n",
    "トラフィック量は気象よりも **曜日と週次の周期パターン** に強く依存していることがわかります。\n",
    "\n",
    "> **改善のヒント**: 祝日フラグやイベント情報を特徴量に追加すると、特異日の予測精度が向上する可能性があります。"
   ],
   "attachments": {}
  },
  {
   "cell_type": "code",
   "id": "c29f1c9c-9cf6-4877-8e94-549b5ebd1f44",
   "metadata": {
    "name": "cell56",
    "language": "python"
   },
   "source": "# ============================================================\n# Model Registry の確認: 登録したモデル一覧\n# ============================================================\n\n# Registry に登録されたモデル一覧\nmodels = reg.show_models()\nprint(\"📦 登録済みモデル一覧:\")\nprint(models[[\"name\", \"comment\"]].to_string(index=False))\n\n# 各モデルのバージョンとメトリクスを確認\nfor model_name in [\"NQ_ISOLATION_FOREST\", \"NQ_TRAFFIC_XGBOOST\"]:\n    m = reg.get_model(model_name)\n    mv = m.version(\"v1\")\n    print(f\"\\n--- {model_name} v1 ---\")\n    print(f\"  メトリクス: {mv.show_metrics()}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "95e38b41-1c2e-483a-a173-46db5d3bd215",
   "metadata": {
    "name": "cell57",
    "language": "python"
   },
   "source": [
    "# ============================================================\n",
    "# Registry 経由の推論デモ: 直近30日の異常検知\n",
    "# ============================================================\n",
    "\n",
    "# 直近30日のデータを取得\n",
    "recent_df = session.sql(\"\"\"\n",
    "    SELECT\n",
    "        nq.MEASURE_DATE,\n",
    "        AVG(nq.CALL_DROP_RATE)          AS CALL_DROP_RATE,\n",
    "        AVG(nq.AVG_DOWNLOAD_MBPS)       AS AVG_DOWNLOAD_MBPS,\n",
    "        AVG(nq.AVG_LATENCY_MS)          AS AVG_LATENCY_MS,\n",
    "        AVG(nq.PACKET_LOSS_RATE)        AS PACKET_LOSS_RATE,\n",
    "        AVG(w.AVG_RAINFALL)             AS PRECIPITATION_MM,\n",
    "        AVG(w.AVG_WIND_SPEED)           AS WIND_SPEED_KMH\n",
    "    FROM TELECOM_AI_HANDSON.ANALYTICS.NETWORK_QUALITY nq\n",
    "    LEFT JOIN TELECOM_AI_HANDSON.ANALYTICS.DAILY_WEATHER w\n",
    "        ON nq.MEASURE_DATE = w.WEATHER_DATE\n",
    "    WHERE nq.MEASURE_DATE >= DATEADD('day', -30, CURRENT_DATE())\n",
    "    GROUP BY nq.MEASURE_DATE\n",
    "    ORDER BY nq.MEASURE_DATE DESC\n",
    "\"\"\").to_pandas()\n",
    "recent_df = recent_df.dropna()\n",
    "\n",
    "# --- ローカルの iso_model で推論 ---\n",
    "recent_pred   = iso_model.predict(recent_df[FEATURE_COLS])\n",
    "recent_scores = iso_model.decision_function(recent_df[FEATURE_COLS])\n",
    "\n",
    "recent_df[\"IS_ANOMALY\"]     = (recent_pred == -1)\n",
    "recent_df[\"ANOMALY_SCORE\"]  = recent_scores\n",
    "\n",
    "anomaly_count = recent_df[\"IS_ANOMALY\"].sum()\n",
    "print(f\"直近30日の異常検知結果: {anomaly_count} 日を異常と判定\")\n",
    "\n",
    "# --- Registry 経由の推論（mv.run → ウェアハウス）---\n",
    "# Snowpark DataFrame のカラム名をモデル登録時と一致させる\n",
    "print(\"\\n--- Registry 経由の推論（上位5件）---\")\n",
    "iso_model_ref = reg.get_model(\"NQ_ISOLATION_FOREST\").version(\"v1\")\n",
    "sample_sp = session.create_dataframe(recent_df[FEATURE_COLS].head(5).reset_index(drop=True))\n",
    "# create_dataframe は Pandas のカラム名をそのまま使うが、大文字に変換されるため\n",
    "# モデル登録時の sample_input_data と一致していれば動作する\n",
    "registry_result = iso_model_ref.run(sample_sp, function_name=\"predict\")\n",
    "registry_result.show()\n",
    "\n",
    "# --- 結果表示 ---\n",
    "recent_df[[\"MEASURE_DATE\", \"CALL_DROP_RATE\", \"PRECIPITATION_MM\",\n",
    "           \"WIND_SPEED_KMH\", \"ANOMALY_SCORE\", \"IS_ANOMALY\"]]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-6789-abcd-ef01-222333444555",
   "metadata": {
    "name": "cell57_explanation"
   },
   "source": [
    "#### 結果の読み方\n",
    "\n",
    "**1. 直近30日の異常検知サマリー**\n",
    "\n",
    "```\n",
    "直近30日の異常検知結果: 9 日を異常と判定\n",
    "```\n",
    "\n",
    "- 直近28日間のうち **9 日（約32%）** が異常と判定されました。  \n",
    "  先ほどのテストデータ全体（13.6%）と比べて異常の割合が高くなっています。  \n",
    "  これは直近データが訓練データ（2022〜2024年）の傾向からより離れていることを示します。\n",
    "\n",
    "**2. Registry 経由の推論（上位5件）**\n",
    "\n",
    "| 日付（推定） | 切断率 | 降水量 | 風速 | 判定 | 注目ポイント |\n",
    "|---|---|---|---|---|---|\n",
    "| 2/24 | 0.217 | 0.2mm | 13.8km/h | **正常** | 全指標が平均的 |\n",
    "| 2/23 | 0.224 | 0.1mm | **27.0km/h** | **異常** | 風速が極端に高い |\n",
    "| 2/22 | 0.220 | 0.0mm | **19.3km/h** | **異常** | 風速がやや高い |\n",
    "| 2/21 | **0.372** | 0.0mm | 8.9km/h | **正常** | 切断率が高いが他指標は平均的 |\n",
    "| 2/20 | 0.211 | 0.0mm | 9.2km/h | **正常** | 全指標が平均的 |\n",
    "\n",
    "- 2/23 と 2/22 が異常判定された主因は **風速** です（27.0km/h, 19.3km/h）。  \n",
    "  訓練データの風速分布から大きく外れたデータとして孤立が検出されています。\n",
    "- 2/21 は切断率 0.372 と高めですが **正常** と判定されています。  \n",
    "  切断率が周期的に跳ねるパターンは訓練データにも存在するため、「見慣れたパターン」として正常扱いされます。  \n",
    "  IsolationForest は **単一指標の高低** ではなく **多次元空間での孤立度** で判定することがわかります。\n",
    "\n",
    "**3. 全30日の詳細テーブル**\n",
    "\n",
    "| カラム | 意味 |\n",
    "|--------|------|\n",
    "| `ANOMALY_SCORE` | 異常スコア。**負の値** = 異常寄り、**正の値** = 正常寄り |\n",
    "| `IS_ANOMALY` | True = 異常、False = 正常 |\n",
    "\n",
    "異常と判定された日のパターンは大きく **2種類** に分かれます：\n",
    "\n",
    "| パターン | 該当日（例） | 特徴 |\n",
    "|----------|-------------|------|\n",
    "| **強風** | 2/23（27km/h）, 2/19（24.3km/h）, 2/8（23km/h） | 風速 20km/h 超。切断率は正常範囲 |\n",
    "| **大雨** | 2/16（10.4mm）, 2/11（9.7mm）, 2/7（11.7mm） | 降水量 10mm 前後。風速も高め |\n",
    "\n",
    "一方、切断率が 0.37 前後に跳ねる日（2/21, 2/15, 2/6）はスコアが **正の値（正常寄り）** です。  \n",
    "これは約5日周期で切断率が上がるパターンが訓練データにも含まれており、  \n",
    "モデルが「よくあるパターン」として学習済みであることを意味します。\n",
    "\n",
    "> **実運用への示唆**: 切断率の高低だけで監視するよりも、  \n",
    "> **気象条件を含む多次元の異常スコア** を組み合わせることで、  \n",
    "> 「通常運用の変動」と「本当に注意すべき異常」を区別できます。"
   ],
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "id": "7594cdca-dd54-4d31-9575-f01c76ca4f5b",
   "metadata": {
    "name": "cell58"
   },
   "source": [
    "### Step 7 まとめ\n",
    "\n",
    "OSS ライブラリと Snowflake の **Container Runtime** + **Model Registry** を使って、カスタム ML パイプラインを構築しました。\n",
    "\n",
    "| モデル | ライブラリ | 用途 | カスタム要素 |\n",
    "|--------|-----------|------|------------|\n",
    "| **IsolationForest** | scikit-learn | 異常検知（教師なし） | `contamination` で異常割合を制御、多次元特徴量で検知 |\n",
    "| **XGBRegressor** | XGBoost | トラフィック予測 | ラグ特徴量・移動平均・カレンダー・気象の特徴量エンジニアリング |\n",
    "\n",
    "#### ML 開発サイクルの全体像\n",
    "\n",
    "```\n",
    "データ取得（Snowpark session.sql → Pandas）\n",
    "     │\n",
    "     ▼\n",
    "特徴量エンジニアリング（Pandas）\n",
    "     │\n",
    "     ▼\n",
    "モデル訓練（scikit-learn / XGBoost）\n",
    "     │\n",
    "     ▼\n",
    "Model Registry に登録（reg.log_model + target_platforms=[\"WAREHOUSE\"]）\n",
    "     │\n",
    "     ▼\n",
    "推論（mv.run で Snowpark DataFrame を渡す → ウェアハウスで実行）\n",
    "     │\n",
    "     ▼\n",
    "Task + Alert で自動化（発展）\n",
    "```\n",
    "\n",
    "> **ポイント**: `target_platforms=[\"WAREHOUSE\"]` を指定して登録すると、ウェアハウス上で `mv.run()` による推論が実行できます。  \n",
    "> **発展**: Model Registry にはバージョン管理機能があるため、モデルを改善したら `v2`, `v3` と登録し、  \n",
    "> `DEFAULT_VERSION` を切り替えることで **ダウンタイムなし** でモデルを更新できます。"
   ],
   "attachments": {}
  }
 ]
}